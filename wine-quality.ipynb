{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of raw dataframe (150930, 11)\n",
      "Shape of cleaned dataframe (114393, 8)\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'wine-data'\n",
    "raw_file = 'winemag-data_first150k.csv'\n",
    "raw_df = pd.read_csv(os.path.join(data_dir, raw_file))\n",
    "\n",
    "print('Shape of raw dataframe {}' .format(raw_df.shape))\n",
    "\n",
    "raw_df.drop(raw_df.columns[0], axis=1, inplace=True)\n",
    "raw_df.drop(['region_2', 'designation'], axis=1, inplace=True)\n",
    "raw_df = raw_df.dropna()\n",
    "\n",
    "print('Shape of cleaned dataframe {}'.format(raw_df.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_age(year):\n",
    "    res = re.findall('.*([1-3][0-9]{3})', year)\n",
    "    res = list(map(int, res))\n",
    "    \n",
    "    if len(res) > 0 and min(res) < 2020:\n",
    "        age = 2020 - min(res)\n",
    "    else:\n",
    "        age = -1\n",
    "        \n",
    "    return age\n",
    "\n",
    "def get_life(year):\n",
    "    res = re.findall('.*([1-3][0-9]{3})', year)\n",
    "    res = list(map(int, res))\n",
    "    \n",
    "    if len(res) > 0 and max(res) > 2020:\n",
    "        life = max(res) - 2020\n",
    "    else:\n",
    "        life = -1\n",
    "        \n",
    "    return life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['age'] = raw_df['description'].apply(get_age)\n",
    "raw_df['life'] = raw_df['description'].apply(get_life)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country                                        description  points  price  \\\n",
      "0      US  This tremendous 100% varietal wine hails from ...      96  235.0   \n",
      "1   Spain  Ripe aromas of fig, blackberry and cassis are ...      96  110.0   \n",
      "2      US  Mac Watson honors the memory of a wine once ma...      96   90.0   \n",
      "3      US  This spent 20 months in 30% new French oak, an...      96   65.0   \n",
      "4  France  This is the top wine from La Bégude, named aft...      95   66.0   \n",
      "\n",
      "         province           region_1             variety  \\\n",
      "0      California        Napa Valley  Cabernet Sauvignon   \n",
      "1  Northern Spain               Toro       Tinta de Toro   \n",
      "2      California     Knights Valley     Sauvignon Blanc   \n",
      "3          Oregon  Willamette Valley          Pinot Noir   \n",
      "4        Provence             Bandol  Provence red blend   \n",
      "\n",
      "                    winery  age  life  \n",
      "0                    Heitz   -1    10  \n",
      "1  Bodega Carmen Rodríguez   -1     3  \n",
      "2                 Macauley   -1    -1  \n",
      "3                    Ponzi   -1    12  \n",
      "4     Domaine de la Bégude   -1    -1  \n"
     ]
    }
   ],
   "source": [
    "print(raw_df.head())\n",
    "raw_df.to_csv(os.path.join(data_dir, 'wine-data-postprocessed.csv'), index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fa83a5b91d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa83857c2e8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa847525588>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fa8360087b8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa83b90f208>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa83a892da0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fa8438c10b8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa835b4efd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fa835b4e208>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_df = pd.read_csv(os.path.join(data_dir, 'wine-data-postprocessed.csv'))\n",
    "raw_df['points'].hist(by=raw_df['country'], figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>age</th>\n",
       "      <th>life</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aglianico</th>\n",
       "      <td>88.671815</td>\n",
       "      <td>33.169884</td>\n",
       "      <td>-0.567568</td>\n",
       "      <td>-0.733591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Airen</th>\n",
       "      <td>81.333333</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albana</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>35.571429</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albariño</th>\n",
       "      <td>87.338374</td>\n",
       "      <td>19.982987</td>\n",
       "      <td>-0.270321</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albarossa</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albarín</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aleatico</th>\n",
       "      <td>85.300000</td>\n",
       "      <td>37.900000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alicante</th>\n",
       "      <td>87.300000</td>\n",
       "      <td>24.300000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alicante Bouschet</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>28.666667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aligoté</th>\n",
       "      <td>85.833333</td>\n",
       "      <td>17.833333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alsace white blend</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>33.647059</td>\n",
       "      <td>-0.254902</td>\n",
       "      <td>0.196078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Altesse</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alvarelhão</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angevine</th>\n",
       "      <td>86.800000</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ansonica</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Apple</th>\n",
       "      <td>89.333333</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arneis</th>\n",
       "      <td>85.873016</td>\n",
       "      <td>19.285714</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auxerrois</th>\n",
       "      <td>89.692308</td>\n",
       "      <td>25.307692</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baco Noir</th>\n",
       "      <td>85.222222</td>\n",
       "      <td>24.222222</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbera</th>\n",
       "      <td>87.331595</td>\n",
       "      <td>25.917623</td>\n",
       "      <td>-0.406674</td>\n",
       "      <td>-0.990615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black Monukka</th>\n",
       "      <td>91.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black Muscat</th>\n",
       "      <td>88.923077</td>\n",
       "      <td>25.923077</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blaufränkisch</th>\n",
       "      <td>87.600000</td>\n",
       "      <td>24.100000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bobal</th>\n",
       "      <td>85.062500</td>\n",
       "      <td>14.687500</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bombino Bianco</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonarda</th>\n",
       "      <td>86.217105</td>\n",
       "      <td>15.046053</td>\n",
       "      <td>-0.822368</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bordeaux-style Red Blend</th>\n",
       "      <td>88.809162</td>\n",
       "      <td>49.790173</td>\n",
       "      <td>0.889153</td>\n",
       "      <td>-0.873012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bordeaux-style White Blend</th>\n",
       "      <td>87.865285</td>\n",
       "      <td>36.740933</td>\n",
       "      <td>1.046632</td>\n",
       "      <td>-0.939551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bovale</th>\n",
       "      <td>86.750000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brachetto</th>\n",
       "      <td>84.166667</td>\n",
       "      <td>18.291667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verdejo-Sauvignon Blanc</th>\n",
       "      <td>85.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verdejo-Viura</th>\n",
       "      <td>85.160000</td>\n",
       "      <td>10.760000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verdelho</th>\n",
       "      <td>86.431373</td>\n",
       "      <td>15.313725</td>\n",
       "      <td>-0.470588</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verdicchio</th>\n",
       "      <td>87.021277</td>\n",
       "      <td>22.063830</td>\n",
       "      <td>-0.276596</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verduzzo</th>\n",
       "      <td>88.875000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Verduzzo Friulano</th>\n",
       "      <td>88.500000</td>\n",
       "      <td>30.700000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermentino</th>\n",
       "      <td>87.015789</td>\n",
       "      <td>23.057895</td>\n",
       "      <td>-0.663158</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermentino Nero</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vernaccia</th>\n",
       "      <td>86.400000</td>\n",
       "      <td>18.923077</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vespaiolo</th>\n",
       "      <td>86.666667</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vidadillo</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vidal</th>\n",
       "      <td>91.250000</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vidal Blanc</th>\n",
       "      <td>86.745098</td>\n",
       "      <td>35.019608</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vignoles</th>\n",
       "      <td>84.142857</td>\n",
       "      <td>15.238095</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viognier</th>\n",
       "      <td>87.349784</td>\n",
       "      <td>23.677922</td>\n",
       "      <td>-0.371429</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viognier-Chardonnay</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viognier-Grenache Blanc</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viognier-Marsanne</th>\n",
       "      <td>87.571429</td>\n",
       "      <td>19.571429</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viognier-Roussanne</th>\n",
       "      <td>89.388889</td>\n",
       "      <td>26.222222</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viognier-Valdiguié</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viura</th>\n",
       "      <td>84.936364</td>\n",
       "      <td>11.827273</td>\n",
       "      <td>-0.827273</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viura-Chardonnay</th>\n",
       "      <td>84.090909</td>\n",
       "      <td>8.727273</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viura-Sauvignon Blanc</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viura-Verdejo</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White Blend</th>\n",
       "      <td>86.987839</td>\n",
       "      <td>22.455566</td>\n",
       "      <td>-0.572030</td>\n",
       "      <td>-0.992984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White Riesling</th>\n",
       "      <td>88.125000</td>\n",
       "      <td>20.843750</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xarel-lo</th>\n",
       "      <td>86.166667</td>\n",
       "      <td>20.958333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zibibbo</th>\n",
       "      <td>90.129032</td>\n",
       "      <td>34.258065</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zinfandel</th>\n",
       "      <td>86.667546</td>\n",
       "      <td>26.777836</td>\n",
       "      <td>0.365172</td>\n",
       "      <td>-0.993668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zweigelt</th>\n",
       "      <td>87.333333</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               points      price        age      life\n",
       "variety                                                              \n",
       "Aglianico                   88.671815  33.169884  -0.567568 -0.733591\n",
       "Airen                       81.333333   8.833333  -1.000000 -1.000000\n",
       "Albana                      90.000000  35.571429  -1.000000 -1.000000\n",
       "Albariño                    87.338374  19.982987  -0.270321 -1.000000\n",
       "Albarossa                   88.000000  40.000000  -1.000000 -1.000000\n",
       "Albarín                     84.000000  15.000000  -1.000000 -1.000000\n",
       "Aleatico                    85.300000  37.900000  -1.000000 -1.000000\n",
       "Alicante                    87.300000  24.300000  -1.000000 -1.000000\n",
       "Alicante Bouschet           87.000000  28.666667  -1.000000 -1.000000\n",
       "Aligoté                     85.833333  17.833333   0.700000 -1.000000\n",
       "Alsace white blend          89.000000  33.647059  -0.254902  0.196078\n",
       "Altesse                     89.000000  18.000000  -1.000000 -1.000000\n",
       "Alvarelhão                  84.000000  18.000000  -1.000000 -1.000000\n",
       "Angevine                    86.800000  12.400000  -1.000000 -1.000000\n",
       "Ansonica                    87.000000  18.000000  -1.000000 -1.000000\n",
       "Apple                       89.333333  31.000000  -1.000000 -1.000000\n",
       "Arneis                      85.873016  19.285714  -0.285714 -1.000000\n",
       "Auxerrois                   89.692308  25.307692  -1.000000 -1.000000\n",
       "Baco Noir                   85.222222  24.222222  -1.000000 -1.000000\n",
       "Barbera                     87.331595  25.917623  -0.406674 -0.990615\n",
       "Black Monukka               91.500000  25.000000  -1.000000 -1.000000\n",
       "Black Muscat                88.923077  25.923077  -1.000000 -1.000000\n",
       "Blaufränkisch               87.600000  24.100000  -0.400000 -1.000000\n",
       "Bobal                       85.062500  14.687500  -1.000000 -1.000000\n",
       "Bombino Bianco              88.000000  30.000000  -1.000000 -1.000000\n",
       "Bonarda                     86.217105  15.046053  -0.822368 -1.000000\n",
       "Bordeaux-style Red Blend    88.809162  49.790173   0.889153 -0.873012\n",
       "Bordeaux-style White Blend  87.865285  36.740933   1.046632 -0.939551\n",
       "Bovale                      86.750000  37.500000  -1.000000 -1.000000\n",
       "Brachetto                   84.166667  18.291667  -1.000000 -1.000000\n",
       "...                               ...        ...        ...       ...\n",
       "Verdejo-Sauvignon Blanc     85.500000  15.000000  -1.000000 -1.000000\n",
       "Verdejo-Viura               85.160000  10.760000  -1.000000 -1.000000\n",
       "Verdelho                    86.431373  15.313725  -0.470588 -1.000000\n",
       "Verdicchio                  87.021277  22.063830  -0.276596 -1.000000\n",
       "Verduzzo                    88.875000  29.000000  -1.000000 -1.000000\n",
       "Verduzzo Friulano           88.500000  30.700000  -1.000000 -1.000000\n",
       "Vermentino                  87.015789  23.057895  -0.663158 -1.000000\n",
       "Vermentino Nero             88.000000  45.000000  -1.000000 -1.000000\n",
       "Vernaccia                   86.400000  18.923077  -1.000000 -1.000000\n",
       "Vespaiolo                   86.666667  20.000000  -1.000000 -1.000000\n",
       "Vidadillo                   89.000000  24.000000  -1.000000 -1.000000\n",
       "Vidal                       91.250000  53.750000  -1.000000 -1.000000\n",
       "Vidal Blanc                 86.745098  35.019608  -1.000000 -1.000000\n",
       "Vignoles                    84.142857  15.238095  -1.000000 -1.000000\n",
       "Viognier                    87.349784  23.677922  -0.371429 -1.000000\n",
       "Viognier-Chardonnay         84.000000  25.000000  -1.000000 -1.000000\n",
       "Viognier-Grenache Blanc     91.000000  27.000000  -1.000000 -1.000000\n",
       "Viognier-Marsanne           87.571429  19.571429  -1.000000 -1.000000\n",
       "Viognier-Roussanne          89.388889  26.222222  -1.000000 -1.000000\n",
       "Viognier-Valdiguié          84.000000  17.000000  -1.000000 -1.000000\n",
       "Viura                       84.936364  11.827273  -0.827273 -1.000000\n",
       "Viura-Chardonnay            84.090909   8.727273  -1.000000 -1.000000\n",
       "Viura-Sauvignon Blanc       84.000000  13.000000  17.000000 -1.000000\n",
       "Viura-Verdejo               83.000000  13.000000  -1.000000 -1.000000\n",
       "White Blend                 86.987839  22.455566  -0.572030 -0.992984\n",
       "White Riesling              88.125000  20.843750  -1.000000 -1.000000\n",
       "Xarel-lo                    86.166667  20.958333   0.750000 -1.000000\n",
       "Zibibbo                     90.129032  34.258065  -1.000000 -1.000000\n",
       "Zinfandel                   86.667546  26.777836   0.365172 -0.993668\n",
       "Zweigelt                    87.333333  25.666667  -1.000000 -1.000000\n",
       "\n",
       "[460 rows x 4 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.groupby(['variety']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_class(points):\n",
    "    if points in range(80,83):\n",
    "        return 0\n",
    "    elif points in range(83,87):\n",
    "        return 1\n",
    "    elif points in range(87,90):\n",
    "        return 2\n",
    "    elif points in range(90,94):\n",
    "        return 3\n",
    "    elif points in range(94-98):\n",
    "        return 4\n",
    "    else:\n",
    "        return 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['rating'] = raw_df['points'].apply(points_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>age</th>\n",
       "      <th>life</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5371</td>\n",
       "      <td>5371</td>\n",
       "      <td>5371</td>\n",
       "      <td>5371</td>\n",
       "      <td>5371</td>\n",
       "      <td>5371</td>\n",
       "      <td>5371</td>\n",
       "      <td>5371</td>\n",
       "      <td>5371</td>\n",
       "      <td>5371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34253</td>\n",
       "      <td>34253</td>\n",
       "      <td>34253</td>\n",
       "      <td>34253</td>\n",
       "      <td>34253</td>\n",
       "      <td>34253</td>\n",
       "      <td>34253</td>\n",
       "      <td>34253</td>\n",
       "      <td>34253</td>\n",
       "      <td>34253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31619</td>\n",
       "      <td>31619</td>\n",
       "      <td>31619</td>\n",
       "      <td>31619</td>\n",
       "      <td>31619</td>\n",
       "      <td>31619</td>\n",
       "      <td>31619</td>\n",
       "      <td>31619</td>\n",
       "      <td>31619</td>\n",
       "      <td>31619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5141</td>\n",
       "      <td>5141</td>\n",
       "      <td>5141</td>\n",
       "      <td>5141</td>\n",
       "      <td>5141</td>\n",
       "      <td>5141</td>\n",
       "      <td>5141</td>\n",
       "      <td>5141</td>\n",
       "      <td>5141</td>\n",
       "      <td>5141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country  description  points  price  province  region_1  variety  \\\n",
       "rating                                                                     \n",
       "0          5371         5371    5371   5371      5371      5371     5371   \n",
       "1         34253        34253   34253  34253     34253     34253    34253   \n",
       "2         38009        38009   38009  38009     38009     38009    38009   \n",
       "3         31619        31619   31619  31619     31619     31619    31619   \n",
       "5          5141         5141    5141   5141      5141      5141     5141   \n",
       "\n",
       "        winery    age   life  \n",
       "rating                        \n",
       "0         5371   5371   5371  \n",
       "1        34253  34253  34253  \n",
       "2        38009  38009  38009  \n",
       "3        31619  31619  31619  \n",
       "5         5141   5141   5141  "
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.groupby(['rating']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_merged_class(points):\n",
    "    if points in range(80,87):\n",
    "        return 0\n",
    "    elif points in range(87,90):\n",
    "        return 1\n",
    "    else: \n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "      <th>age</th>\n",
       "      <th>life</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39624</td>\n",
       "      <td>39624</td>\n",
       "      <td>39624</td>\n",
       "      <td>39624</td>\n",
       "      <td>39624</td>\n",
       "      <td>39624</td>\n",
       "      <td>39624</td>\n",
       "      <td>39624</td>\n",
       "      <td>39624</td>\n",
       "      <td>39624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "      <td>38009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36760</td>\n",
       "      <td>36760</td>\n",
       "      <td>36760</td>\n",
       "      <td>36760</td>\n",
       "      <td>36760</td>\n",
       "      <td>36760</td>\n",
       "      <td>36760</td>\n",
       "      <td>36760</td>\n",
       "      <td>36760</td>\n",
       "      <td>36760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country  description  points  price  province  region_1  variety  \\\n",
       "rating                                                                     \n",
       "0         39624        39624   39624  39624     39624     39624    39624   \n",
       "1         38009        38009   38009  38009     38009     38009    38009   \n",
       "2         36760        36760   36760  36760     36760     36760    36760   \n",
       "\n",
       "        winery    age   life  \n",
       "rating                        \n",
       "0        39624  39624  39624  \n",
       "1        38009  38009  38009  \n",
       "2        36760  36760  36760  "
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['rating'] = raw_df['points'].apply(points_to_merged_class)\n",
    "raw_df.groupby(['rating']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['price'] = raw_df['price'].astype(int).astype(str)\n",
    "raw_df['feature_string'] = raw_df[['country', 'province', 'region_1', 'winery', 'variety', 'price', 'description']]\\\n",
    ".agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country                                        description  points price  \\\n",
      "0      US  This tremendous 100% varietal wine hails from ...      96   235   \n",
      "1   Spain  Ripe aromas of fig, blackberry and cassis are ...      96   110   \n",
      "2      US  Mac Watson honors the memory of a wine once ma...      96    90   \n",
      "3      US  This spent 20 months in 30% new French oak, an...      96    65   \n",
      "4  France  This is the top wine from La Bégude, named aft...      95    66   \n",
      "\n",
      "         province           region_1             variety  \\\n",
      "0      California        Napa Valley  Cabernet Sauvignon   \n",
      "1  Northern Spain               Toro       Tinta de Toro   \n",
      "2      California     Knights Valley     Sauvignon Blanc   \n",
      "3          Oregon  Willamette Valley          Pinot Noir   \n",
      "4        Provence             Bandol  Provence red blend   \n",
      "\n",
      "                    winery  age  life  rating  \\\n",
      "0                    Heitz   -1    10       2   \n",
      "1  Bodega Carmen Rodríguez   -1     3       2   \n",
      "2                 Macauley   -1    -1       2   \n",
      "3                    Ponzi   -1    12       2   \n",
      "4     Domaine de la Bégude   -1    -1       2   \n",
      "\n",
      "                                      feature_string  \n",
      "0  US California Napa Valley Heitz Cabernet Sauvi...  \n",
      "1  Spain Northern Spain Toro Bodega Carmen Rodríg...  \n",
      "2  US California Knights Valley Macauley Sauvigno...  \n",
      "3  US Oregon Willamette Valley Ponzi Pinot Noir 6...  \n",
      "4  France Provence Bandol Domaine de la Bégude Pr...  \n"
     ]
    }
   ],
   "source": [
    "print(raw_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "def feature_to_words(text):\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
    "    words = text.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['feature_words'] = raw_df['feature_string'].apply(feature_to_words)\n",
    "raw_df.drop(['feature_string'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country                                        description  points price  \\\n",
      "0      US  This tremendous 100% varietal wine hails from ...      96   235   \n",
      "1   Spain  Ripe aromas of fig, blackberry and cassis are ...      96   110   \n",
      "2      US  Mac Watson honors the memory of a wine once ma...      96    90   \n",
      "3      US  This spent 20 months in 30% new French oak, an...      96    65   \n",
      "4  France  This is the top wine from La Bégude, named aft...      95    66   \n",
      "\n",
      "         province           region_1             variety  \\\n",
      "0      California        Napa Valley  Cabernet Sauvignon   \n",
      "1  Northern Spain               Toro       Tinta de Toro   \n",
      "2      California     Knights Valley     Sauvignon Blanc   \n",
      "3          Oregon  Willamette Valley          Pinot Noir   \n",
      "4        Provence             Bandol  Provence red blend   \n",
      "\n",
      "                    winery  rating  \\\n",
      "0                    Heitz       2   \n",
      "1  Bodega Carmen Rodríguez       2   \n",
      "2                 Macauley       2   \n",
      "3                    Ponzi       2   \n",
      "4     Domaine de la Bégude       2   \n",
      "\n",
      "                                       feature_words  \n",
      "0  [us, california, napa, valley, heitz, cabernet...  \n",
      "1  [spain, northern, spain, toro, bodega, carmen,...  \n",
      "2  [us, california, knight, valley, macauley, sau...  \n",
      "3  [us, oregon, willamett, valley, ponzi, pinot, ...  \n",
      "4  [franc, provenc, bandol, domain, de, la, b, gu...  \n"
     ]
    }
   ],
   "source": [
    "raw_df.drop(['age', 'life'], axis=1, inplace=True)\n",
    "print(raw_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.drop(['country', 'points', 'price', 'province', 'region_1', 'variety', 'winery', 'description'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating                                      feature_words\n",
      "0       2  [us, california, napa, valley, heitz, cabernet...\n",
      "1       2  [spain, northern, spain, toro, bodega, carmen,...\n",
      "2       2  [us, california, knight, valley, macauley, sau...\n",
      "3       2  [us, oregon, willamett, valley, ponzi, pinot, ...\n",
      "4       2  [franc, provenc, bandol, domain, de, la, b, gu...\n"
     ]
    }
   ],
   "source": [
    "print(raw_df.head())\n",
    "raw_df.to_csv(os.path.join(data_dir, 'wine-data-postprocessed.csv'), index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train set 91514 and length of test set 22879\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(raw_df, test_size=0.2)\n",
    "print('Length of train set {} and length of test set {}'.format(len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_dict(data, vocab_size = 5000):\n",
    "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
    "    \n",
    "    # TODO: Determine how often each word appears in `data`. Note that `data` is a list of sentences and that a\n",
    "    #       sentence is a list of words.\n",
    "    \n",
    "    word_count = {} # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    all_words = [word for review in data for word in review] # flatten all reviews into one list\n",
    "    word_count = Counter(all_words)\n",
    "    \n",
    "    # TODO: Sort the words found in `data` so that sorted_words[0] is the most frequently appearing word and\n",
    "    #       sorted_words[-1] is the least frequently appearing word.\n",
    "    \n",
    "    word_count_sorted = sorted([(word_count[key], key) for key in word_count.keys()], key=lambda x: x[0], reverse=True)\n",
    "    sorted_words = [pair[1] for pair in word_count_sorted]\n",
    "        \n",
    "    word_dict = {} # This is what we are building, a dictionary that translates words into integers\n",
    "    for idx, word in enumerate(sorted_words[:vocab_size - 2]): # The -2 is so that we save room for the 'no word'\n",
    "        word_dict[word] = idx + 2                              # 'infrequent' labels\n",
    "        \n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = build_dict(train['feature_words'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wine', 'flavor', 'us', 'fruit', 'california']\n"
     ]
    }
   ],
   "source": [
    "print([list(word_dict.keys())[list(word_dict.values()).index(p)] for p in range(2,7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(data_dir, 'word_dict.pkl'), \"wb\") as f:\n",
    "    pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(word_dict, sentence, pad=50):\n",
    "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
    "    INFREQ = 1 # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
    "    \n",
    "    working_sentence = [NOWORD] * pad\n",
    "    \n",
    "    for word_index, word in enumerate(sentence[:pad]):\n",
    "        if word in word_dict:\n",
    "            working_sentence[word_index] = word_dict[word]\n",
    "        else:\n",
    "            working_sentence[word_index] = INFREQ\n",
    "            \n",
    "    return working_sentence, min(len(sentence), pad)\n",
    "\n",
    "def convert_and_pad_data(word_dict, data, pad=50):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convert_and_pad(word_dict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "        \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_X_len = convert_and_pad_data(word_dict, train['feature_words'].to_list())\n",
    "test_X, test_X_len = convert_and_pad_data(word_dict, test['feature_words'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y = pd.get_dummies(train['rating'], prefix='rating').to_numpy()\n",
    "#test_y = pd.get_dummies(test['rating'], prefix='rating').to_numpy()\n",
    "train_y = train['rating'].to_numpy()\n",
    "test_y = test['rating'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   4   48  121    7  108 4880  273  299 1299  266  162 1755  116  418\n",
      "    3  623  308  175  171  403  594   31   35  705  785    2  613    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0] 0\n"
     ]
    }
   ],
   "source": [
    "print(train_X[25], train_y[25])\n",
    "#np.where((test_y == (0, 0, 0)).all(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(train_y), pd.DataFrame(train_X_len), pd.DataFrame(train_X)], axis=1) \\\n",
    "        .to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/wine_lstm'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::816484814286:role/service-role/AmazonSageMaker-ExecutionRole-20200205T171423\n"
     ]
    }
   ],
   "source": [
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-ap-southeast-1-816484814286/sagemaker/wine_lstm\n"
     ]
    }
   ],
   "source": [
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "# Read in only the first 250 rows\n",
    "train_sample = pd.read_csv(os.path.join(data_dir, 'train.csv'), header=None, names=None, nrows=250)\n",
    "\n",
    "# Turn the input pandas dataframe into tensors\n",
    "train_sample_y = torch.from_numpy(train_sample[[0]].values).long().squeeze()\n",
    "train_sample_X = torch.from_numpy(train_sample.drop([0], axis=1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "train_sample_ds = torch.utils.data.TensorDataset(train_sample_X, train_sample_y)\n",
    "# Build the dataloader\n",
    "train_sample_dl = torch.utils.data.DataLoader(train_sample_ds, shuffle=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, optimizer, loss_fn, device):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:         \n",
    "            batch_X, batch_y = batch\n",
    "            \n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            # TODO: Complete this train method to train the model provided.\n",
    "            output = model(batch_X)      \n",
    "            loss = loss_fn(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.data.item()\n",
    "        print(\"Epoch: {}, CELoss: {}\".format(epoch, total_loss / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/wine-score/train/model.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(out.squeeze())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, CELoss: 1.099537205696106\n",
      "Epoch: 2, CELoss: 1.0973148822784424\n",
      "Epoch: 3, CELoss: 1.095057201385498\n",
      "Epoch: 4, CELoss: 1.0924098491668701\n",
      "Epoch: 5, CELoss: 1.0897857904434205\n",
      "Epoch: 6, CELoss: 1.087044358253479\n",
      "Epoch: 7, CELoss: 1.0841856241226195\n",
      "Epoch: 8, CELoss: 1.0811221837997436\n",
      "Epoch: 9, CELoss: 1.0777692556381226\n",
      "Epoch: 10, CELoss: 1.0741156578063964\n",
      "Epoch: 11, CELoss: 1.0700961112976075\n",
      "Epoch: 12, CELoss: 1.0657296419143676\n",
      "Epoch: 13, CELoss: 1.0608441591262818\n",
      "Epoch: 14, CELoss: 1.0553647518157958\n",
      "Epoch: 15, CELoss: 1.0494439125061035\n",
      "Epoch: 16, CELoss: 1.0433729410171508\n",
      "Epoch: 17, CELoss: 1.0361740112304687\n",
      "Epoch: 18, CELoss: 1.0288588047027587\n",
      "Epoch: 19, CELoss: 1.0210612297058106\n",
      "Epoch: 20, CELoss: 1.0128722786903381\n",
      "Epoch: 21, CELoss: 1.003906798362732\n",
      "Epoch: 22, CELoss: 0.9944669842720032\n",
      "Epoch: 23, CELoss: 0.9850926876068116\n",
      "Epoch: 24, CELoss: 0.9745045661926269\n",
      "Epoch: 25, CELoss: 0.9635182023048401\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from train.model import LSTMClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMClassifier(32, 6, 5000).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train(model, train_sample_dl, 25, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"train\",\n",
    "                    role=role,\n",
    "                    framework_version='0.4.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 10,\n",
    "                        'hidden_dim': 6,\n",
    "                        'embedding_dim': 16,\n",
    "                        'vocab_size': 5000,\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-17 00:30:47 Starting - Starting the training job...\n",
      "2020-03-17 00:30:49 Starting - Launching requested ML instances......\n",
      "2020-03-17 00:31:50 Starting - Preparing the instances for training......\n",
      "2020-03-17 00:33:18 Downloading - Downloading input data...\n",
      "2020-03-17 00:33:47 Training - Downloading the training image.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-03-17 00:34:26,810 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-03-17 00:34:26,835 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-03-17 00:34:29,857 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-03-17 00:34:30,083 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-03-17 00:34:30,084 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-03-17 00:34:30,084 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-03-17 00:34:30,084 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mCollecting pandas (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\u001b[0m\n",
      "\u001b[34mCollecting numpy (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/52/e6/1715e592ef47f28f3f50065322423bb75619ed2f7c24be86380ecc93503c/numpy-1.18.1-cp35-cp35m-manylinux1_x86_64.whl (19.9MB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas->-r requirements.txt (line 1)) (2.7.5)\u001b[0m\n",
      "\u001b[34mCollecting pytz>=2011k (from pandas->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.5/dist-packages (from nltk->-r requirements.txt (line 3)) (1.11.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, train\n",
      "  Running setup.py bdist_wheel for nltk: started\n",
      "  Running setup.py bdist_wheel for nltk: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "  Running setup.py bdist_wheel for train: started\u001b[0m\n",
      "\u001b[34m  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-s2k19czr/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: numpy, pytz, pandas, nltk, train\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\u001b[0m\n",
      "\n",
      "2020-03-17 00:34:26 Training - Training image download completed. Training in progress.\u001b[34m      Successfully uninstalled numpy-1.15.4\u001b[0m\n",
      "\u001b[34mSuccessfully installed nltk-3.4.5 numpy-1.18.1 pandas-0.24.2 pytz-2019.3 train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-03-17 00:34:41,335 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-1-816484814286/sagemaker-pytorch-2020-03-17-00-30-47-281/source/sourcedir.tar.gz\",\n",
      "    \"log_level\": 20,\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ]\n",
      "    },\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"job_name\": \"sagemaker-pytorch-2020-03-17-00-30-47-281\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"module_name\": \"train\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"hyperparameters\": {\n",
      "        \"hidden_dim\": 6,\n",
      "        \"embedding_dim\": 16,\n",
      "        \"epochs\": 10,\n",
      "        \"vocab_size\": 5000\n",
      "    },\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"num_gpus\": 1,\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"user_entry_point\": \"train.py\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_EMBEDDING_DIM=16\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=6\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"embedding_dim\":16,\"epochs\":10,\"hidden_dim\":6,\"vocab_size\":5000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"sagemaker-pytorch-2020-03-17-00-30-47-281\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-1-816484814286/sagemaker-pytorch-2020-03-17-00-30-47-281/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_HP_VOCAB_SIZE=5000\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-1-816484814286/sagemaker-pytorch-2020-03-17-00-30-47-281/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_HPS={\"embedding_dim\":16,\"epochs\":10,\"hidden_dim\":6,\"vocab_size\":5000}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--embedding_dim\",\"16\",\"--epochs\",\"10\",\"--hidden_dim\",\"6\",\"--vocab_size\",\"5000\"]\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --embedding_dim 16 --epochs 10 --hidden_dim 6 --vocab_size 5000\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mModel loaded with embedding_dim 16, hidden_dim 6, vocab_size 5000.\u001b[0m\n",
      "\u001b[34mEpoch: 1, CELoss: 1.0747491134611589\u001b[0m\n",
      "\u001b[34mEpoch: 2, CELoss: 0.9557442994757072\u001b[0m\n",
      "\u001b[34mEpoch: 3, CELoss: 0.9254398042929239\u001b[0m\n",
      "\u001b[34mEpoch: 4, CELoss: 0.8904686064027542\u001b[0m\n",
      "\u001b[34mEpoch: 5, CELoss: 0.8740343404881781\u001b[0m\n",
      "\u001b[34mEpoch: 6, CELoss: 0.8576871456380663\u001b[0m\n",
      "\u001b[34mEpoch: 7, CELoss: 0.8397245949873046\u001b[0m\n",
      "\n",
      "2020-03-17 00:35:17 Uploading - Uploading generated training model\u001b[34mEpoch: 8, CELoss: 0.8323159940415921\u001b[0m\n",
      "\u001b[34mEpoch: 9, CELoss: 0.8240176702344884\u001b[0m\n",
      "\u001b[34mEpoch: 10, CELoss: 0.8153054021590249\u001b[0m\n",
      "\u001b[34m2020-03-17 00:35:12,402 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-03-17 00:35:24 Completed - Training job completed\n",
      "Training seconds: 126\n",
      "Billable seconds: 126\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-pytorch-2020-03-17-00-30-47-281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "# TODO: Deploy the trained model\n",
    "predictor = estimator.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pd.concat([pd.DataFrame(test_X_len), pd.DataFrame(test_X)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into chunks and send each chunk seperately, accumulating the results.\n",
    "\n",
    "def predict(data, rows=512):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = np.array([])\n",
    "    for array in split_array:\n",
    "        predictions = np.append(predictions, predictor.predict(array))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:[0.9999250173568726, 7.465887028956786e-05, 3.471247680408851e-07] Actual:1\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(test_X.values).tolist()\n",
    "#predictions = [num for num in predictions]\n",
    "print('Predictions:{}'.format(predictions[0:3]), 'Actual:{}'.format(test_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22879\n",
      "Predictions:1 Actual:0\n"
     ]
    }
   ],
   "source": [
    "predictions_consolidated = [predictions[x:x+3].index(max(predictions[x:x+3])) for x in range(0, len(predictions), 3)]\n",
    "print(len(predictions_consolidated))\n",
    "print('Predictions:{}'.format(predictions_consolidated[5]), 'Actual:{}'.format(test_y[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5840, 1686,  381],\n",
       "       [1672, 3899, 2076],\n",
       "       [ 212, 1548, 5565]])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "accuracy_score(test_y, predictions_consolidated)\n",
    "confusion_matrix(test_y, predictions_consolidated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
